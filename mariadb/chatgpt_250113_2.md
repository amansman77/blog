# ChatGPT 와 대화한 내용

--- 질문1

질문: MariaDB(10.6.18) 에서 클러스터링의 기본 설정이 멀티 마스터인 이유가 있을까?

답변: MariaDB(10.6.18)에서 클러스터링 기본 설정이 멀티 마스터(Multi-Master)인 이유는 Galera Cluster의 설계와 데이터베이스 고가용성 및 확장성 목표에 기반합니다. 아래에 주요 이유를 정리합니다.

---

### 1. **고가용성 (High Availability)**
멀티 마스터 설정은 클러스터 내의 모든 노드가 데이터 읽기 및 쓰기 요청을 처리할 수 있게 합니다. 따라서 한 노드가 장애가 발생하더라도 다른 노드가 이를 대체할 수 있어 **무중단 서비스**를 제공할 수 있습니다. 이는 단일 마스터 구조의 단점인 SPOF(Single Point of Failure) 문제를 해결합니다.

---

### 2. **로드 밸런싱 (Load Balancing)**
멀티 마스터 환경에서는 각 노드가 읽기/쓰기 작업을 분산 처리합니다. 클라이언트가 특정 노드에 집중되지 않기 때문에 **부하 분산**이 가능하며, 특히 대규모 트랜잭션 처리 환경에서 효율적입니다. 이를 통해 시스템 성능이 향상되고 확장성이 높아집니다.

---

### 3. **다중 데이터 센터 지원**
멀티 마스터 설정은 지리적으로 분산된 데이터 센터 환경에서 유용합니다. 예를 들어, 각 지역의 사용자 요청이 가장 가까운 노드에서 처리되도록 설정하면 **네트워크 대기 시간을 최소화**할 수 있습니다.

---

### 4. **데이터 일관성 유지**
Galera Cluster는 **동기식 복제(Synchronous Replication)**를 사용하여 모든 노드에 데이터의 일관성을 유지합니다. 각 노드가 동시에 데이터를 업데이트하므로 멀티 마스터 구조에서도 데이터 무결성을 유지할 수 있습니다.

---

### 5. **장애 복구 간소화**
멀티 마스터 구조는 장애 복구를 보다 간단하게 만듭니다. 한 노드가 복구되면 클러스터 내 다른 노드로부터 데이터를 복제받아 동기화 상태를 자동으로 복원할 수 있습니다.

---

### 6. **쓰기 가능 노드 확장**
일반적인 Master-Slave 구조에서는 쓰기 가능한 노드가 하나로 제한되지만, Multi-Master 구조에서는 **모든 노드에서 쓰기가 가능**하기 때문에 확장성이 뛰어납니다. 이는 여러 애플리케이션 인스턴스가 동시에 쓰기 작업을 수행해야 하는 환경에서 특히 중요합니다.

---

### 멀티 마스터의 도입 배경: Galera Cluster의 설계 철학
Galera Cluster는 MariaDB 클러스터링을 위해 설계된 라이브러리로, **복제 가능한 모든 노드가 동등하게 작동할 수 있는 구조**를 기본으로 합니다. 이 철학은 다음과 같은 장점을 목표로 합니다:

- 클러스터 구성의 단순화: 노드 간 역할 구분이 없어 설정과 유지 관리가 간단해짐.
- 데이터 안정성과 확장성의 동시 확보.
- 읽기/쓰기 트래픽의 균형 분배.

---

### 한계와 고려 사항
멀티 마스터 구조는 강력하지만, 다음과 같은 점을 고려해야 합니다:

1. **충돌 관리:** 동기식 복제 환경에서도 **충돌(conflict)**이 발생할 수 있으므로 이를 해결하기 위한 설계가 필요합니다.
2. **네트워크 대역폭:** 동기식 복제를 위해 높은 네트워크 대역폭이 필요하며, 네트워크 지연이 클러스터 성능에 영향을 미칠 수 있습니다.
3. **쓰기 집중 환경:** 쓰기 요청이 집중되는 워크로드에서는 멀티 마스터 구조가 오히려 성능 병목을 초래할 수 있습니다.

---

### 결론
멀티 마스터 구조는 고가용성과 확장성을 위해 설계된 Galera Cluster의 핵심 철학입니다. 이로 인해 MariaDB에서 기본 설정으로 채택된 것입니다. 그러나 특정 환경에서는 단일 마스터나 리드-레플리카(Read-Replica) 구조가 더 적합할 수 있으니, **워크로드 특성에 따라 설정을 조정**하는 것이 중요합니다.

--- 질문2

질문: 어떤 워크로드에서 리드-레플리카 구조를 적용하면 좋을까?

답변: 리드-레플리카(Read-Replica) 구조는 읽기 트래픽이 많은 워크로드에서 효율적이며, 쓰기 작업이 상대적으로 적거나 쓰기 작업을 특정 시간에 몰아서 처리할 수 있는 경우에 적합합니다. 아래는 리드-레플리카 구조가 적합한 워크로드와 적용 이유를 정리한 내용입니다.

---

## 1. **읽기 트래픽이 많은 워크로드**
- **예시:** 콘텐츠 제공 플랫폼, 검색 엔진, 데이터 분석 서비스.
- **적용 이유:** 리드-레플리카 구조에서는 마스터(리드) 노드가 쓰기 작업을 처리하고, 복제본(레플리카) 노드가 읽기 작업을 처리합니다. 따라서 읽기 요청이 많은 경우 레플리카를 여러 개 추가하여 부하를 분산시킬 수 있습니다.

---

## 2. **읽기와 쓰기 트래픽의 비율이 불균형한 워크로드**
- **예시:** 전자상거래 웹사이트, 뉴스 사이트.
- **적용 이유:** 읽기 트래픽이 쓰기 트래픽에 비해 훨씬 많은 경우, 레플리카를 활용하여 읽기 작업을 분산하고 마스터 노드의 부하를 줄일 수 있습니다.

---

## 3. **데이터 분석 및 보고**
- **예시:** 데이터 웨어하우스, BI(Business Intelligence) 도구를 사용하는 환경.
- **적용 이유:** 분석 작업이나 보고서 생성을 위해 데이터를 반복적으로 읽는 경우, 레플리카 노드에서 읽기 작업을 수행하면 마스터 노드가 쓰기 작업에 집중할 수 있습니다.

---

## 4. **지리적으로 분산된 사용자**
- **예시:** 글로벌 사용자를 대상으로 하는 애플리케이션.
- **적용 이유:** 지리적으로 분산된 데이터 센터에 레플리카를 배포하여 각 지역 사용자에게 더 낮은 대기 시간(Latency)을 제공할 수 있습니다. 이로써 사용자 경험이 향상됩니다.

---

## 5. **읽기 지연에 민감한 애플리케이션**
- **예시:** 실시간 대시보드, 실시간 통계 시스템.
- **적용 이유:** 레플리카에서 읽기 요청을 처리하면 읽기 작업의 응답 시간이 단축되고, 실시간 데이터를 처리하기에 적합한 환경을 제공합니다.

---

## 6. **비용 최적화가 필요한 환경**
- **예시:** 클라우드에서 비용 민감한 워크로드.
- **적용 이유:** 쓰기 작업을 처리하는 고성능 마스터 노드와 달리, 읽기 전용 레플리카는 상대적으로 저사양의 인스턴스로 구성할 수 있어 비용 절감이 가능합니다.

---

## 7. **데이터 손실 위험이 낮은 경우**
- **예시:** 캐싱된 데이터, 실시간 동기화가 필요하지 않은 데이터.
- **적용 이유:** 리드-레플리카 구조는 마스터에서 레플리카로 데이터가 비동기적으로 복제되므로, 데이터 손실 위험이 낮거나 데이터의 실시간 일관성이 중요하지 않은 경우에 적합합니다.

---

## 리드-레플리카 구조가 부적합한 경우
리드-레플리카 구조는 아래와 같은 경우에는 적합하지 않을 수 있습니다:
1. **쓰기 트래픽이 많고 데이터의 일관성이 중요한 경우**
   - 실시간으로 동기화가 필요한 금융 거래 시스템 등.
2. **쓰기와 읽기 비율이 균형을 이루는 경우**
   - 멀티 마스터 구조가 더 적합할 수 있습니다.
3. **비동기 복제의 데이터 지연이 문제를 일으킬 수 있는 경우**
   - 데이터 일관성이 매우 중요한 워크로드에서는 동기 복제(Multi-Master)가 더 나을 수 있습니다.

---

### 결론
리드-레플리카 구조는 읽기 트래픽이 많고 데이터 일관성 요구가 비교적 낮은 워크로드에 적합합니다. 읽기 요청을 효율적으로 분산시켜 성능을 최적화하며, 비용 절감과 사용자 경험 개선에도 기여할 수 있습니다. 다만, 워크로드 특성과 일관성 요구 사항에 따라 클러스터링 구조를 신중히 선택하는 것이 중요합니다.

--- 질문3

질문: 구성하고자 하는 워크로드의 목적은 HA 야. 2개의 노드를 구성해서 한 노드에 장애가 생겼을 때, 다은 노드로 활용해서 서비스의 지속성을 높이고자해.

답변: HA(High Availability)를 목적으로 두 개의 노드로 구성된 MariaDB 클러스터링 워크로드를 설계하려면, 다음과 같은 고려사항과 설정 방식을 따를 수 있습니다. 이 구성은 노드 장애 발생 시 서비스의 지속성을 보장하는 것을 목표로 합니다.

---

## **추천 아키텍처: Galera Cluster 기반 Multi-Master**

### 이유:
1. **장애 복구**: 두 노드 모두 읽기/쓰기 작업이 가능하여, 한 노드가 장애를 일으키면 다른 노드가 즉시 서비스를 대체할 수 있습니다.
2. **동기 복제**: Galera Cluster는 동기 복제를 사용하여 데이터 일관성을 유지합니다.
3. **자동 장애 복구**: 클러스터 노드는 장애 복구 시 데이터를 자동으로 동기화합니다.

---

## **구성 요소**
1. **MariaDB 10.6.18 with Galera Cluster**: 동기 복제를 지원하는 멀티 마스터 클러스터.
2. **두 개의 EC2 인스턴스**: MariaDB 노드를 실행할 서버.
   - **Public Subnet**: 외부 접근을 허용하거나,
   - **Private Subnet + Load Balancer**: 외부 접근은 로드 밸런서를 통해 관리.
3. **로드 밸런서 (선택사항)**:
   - 장애 노드가 발생해도 클라이언트는 서비스에 영향을 받지 않도록 자동으로 정상 노드로 요청을 라우팅.

---

## **설정 과정**

### 1. **서버 환경 준비**
- EC2 인스턴스 2대 생성 (Ubuntu 20.04 또는 CentOS 추천).
- MariaDB 및 Galera Cluster 설치.

**MariaDB 설치 명령**:
```bash
sudo apt update
sudo apt install mariadb-server galera-4
```

---

### 2. **Galera Cluster 설정**
`/etc/mysql/mariadb.conf.d/galera.cnf` 파일을 편집하여 다음을 추가 또는 수정:

**공통 설정**:
```ini
[mysqld]
bind-address=0.0.0.0
default_storage_engine=InnoDB
innodb_autoinc_lock_mode=2
binlog_format=row

# Galera 설정
wsrep_on=ON
wsrep_provider=/usr/lib/galera/libgalera_smm.so
wsrep_cluster_address="gcomm://<노드1_IP>,<노드2_IP>"
wsrep_cluster_name="mariadb_cluster"
wsrep_node_name=<노드별_이름>
wsrep_node_address=<현재_노드_IP>
wsrep_sst_method=rsync
```

**노드별 wsrep_node_name 및 wsrep_node_address**는 각 인스턴스의 고유 이름과 IP로 설정합니다.

---

### 3. **클러스터 초기화**
첫 번째 노드에서 클러스터 초기화:
```bash
sudo galera_new_cluster
```

두 번째 노드를 시작:
```bash
sudo systemctl start mariadb
```

---

### 4. **서비스 지속성을 위한 HA 구성**
#### **1) 로드 밸런서 설정 (선택 사항)**
- AWS Elastic Load Balancer(ELB)를 사용하여 두 노드의 연결 상태를 모니터링하고, 장애 발생 시 요청을 정상 노드로 라우팅.

#### **2) 클라이언트 연결 설정**
클라이언트는 클러스터 노드 중 하나에 연결하지만, 드라이버에서 연결 장애를 자동으로 처리할 수 있도록 설정합니다.

**MariaDB Connector Example**:
```java
jdbc:mysql:loadbalance://<노드1_IP>,<노드2_IP>/<DB_NAME>?autoReconnect=true
```

---

### 5. **장애 테스트**
- 한 노드를 강제로 종료(`sudo systemctl stop mariadb`).
- 클러스터가 장애 노드를 감지하고 정상적으로 작동하는지 확인.
- 종료된 노드를 복구한 후, 클러스터 재참여 여부 확인.

---

### 6. **운영 고려사항**
1. **헬스체크**: 
   - 노드 상태를 확인하기 위한 헬스 체크 스크립트를 설정.
   - 로드 밸런서의 헬스 체크 설정에 적용.
   
2. **장애 복구 자동화**:
   - 노드 장애 발생 시 자동 복구를 위한 스크립트와 모니터링 도구 설정(e.g., Prometheus, Grafana).

3. **데이터 백업**:
   - 장애 상황에서도 데이터 복구가 가능하도록 정기적으로 백업 수행.

---

## **결론**
두 노드 MariaDB 클러스터로 HA를 구성하려면 Galera Cluster를 사용한 멀티 마스터 설정이 적합합니다. 추가적으로, 로드 밸런서를 활용하거나 클라이언트 드라이버의 장애 복구 옵션을 설정하여 서비스의 지속성을 강화할 수 있습니다. 설정 후에는 정기적인 장애 테스트와 모니터링을 통해 안정성을 검증하세요.

--- 질문4

질문: Galera Cluster를 사용한 멀티 마스터 설정에서 가장 걱정이 되는 부분은 데드락 이슈야. Galera Cluster는 데드락의 위험을 어떻게 관리하고 있는지 분석하고 설명해줘.

답변: Galera Cluster는 멀티 마스터 구조와 동기식 복제를 지원하기 때문에 데드락(Deadlock) 위험이 존재할 수 있습니다. 그러나, Galera는 데드락 가능성을 최소화하고 효율적으로 관리하기 위해 **글로벌 트랜잭션 순서 관리**와 **동기 복제 프로토콜**을 사용합니다. 아래에 Galera Cluster가 데드락 문제를 어떻게 관리하는지 상세히 분석하고 설명합니다.

---

## 1. **Galera Cluster의 동기 복제 메커니즘**
Galera Cluster는 **동기 복제(Synchronous Replication)**를 사용하여 모든 노드에서 동일한 트랜잭션 상태를 유지합니다. 이를 통해 데이터 일관성을 보장하지만, 여러 노드에서 동시에 쓰기 작업이 발생하면 충돌 및 데드락 가능성이 생깁니다.

### 핵심 개념: Write-Set Replication
- Galera는 트랜잭션이 커밋되기 전에 **Write-Set**을 생성하고, 이를 클러스터 내 모든 노드에 전파합니다.
- 트랜잭션이 다른 노드에 적용되기 전에 **글로벌 순서(Global Ordering)**가 결정되며, 이 과정에서 충돌 및 데드락 관리가 이루어집니다.

---

## 2. **데드락 관리 방법**

### (1) **전역 순서 보장 (Global Transaction Ordering)**
Galera Cluster는 트랜잭션에 대해 **전역 순서**를 부여합니다. 이를 통해 트랜잭션 충돌을 감지하고, 데드락 발생 가능성을 줄입니다.
- **Galera Certifier**: 각 노드에서 Write-Set이 수신되면, Galera Certifier가 트랜잭션의 충돌 가능성을 검증합니다.
- **Conflict Detection**: 동일한 데이터에 대해 경쟁하는 트랜잭션은 **충돌이 발생한 노드에서 즉시 중단(Rollback)**됩니다.

### (2) **충돌 검증 (Certification Process)**
Galera의 충돌 검증 과정은 다음 단계를 따릅니다:
1. Write-Set이 클러스터에 전파되기 전, 로컬 트랜잭션이 먼저 충돌 검증을 수행합니다.
2. Write-Set이 다른 노드로 전파되면서, 이미 커밋된 트랜잭션과 충돌 여부를 다시 확인합니다.
3. 충돌이 발견되면 해당 트랜잭션은 롤백됩니다.

이 과정에서 데드락이 발생할 가능성을 **사전에 차단**합니다.

### (3) **노드 간 충돌 해결**
- 충돌이 발생한 경우 Galera는 트랜잭션을 강제로 중단하고, 클라이언트에게 롤백 오류를 반환합니다.
- 이는 데드락으로 인해 시스템이 멈추는 상황을 방지하며, 노드가 정지 상태에 빠지지 않도록 보장합니다.

---

## 3. **Galera Cluster의 데드락 위험 감소 기법**

### (1) **락 기반 동기화가 아닌 Write-Set 검증**
Galera는 전통적인 데이터베이스처럼 **락(Lock)을 사용하지 않고**, Write-Set을 기반으로 동기화를 수행합니다. 이는 데드락의 주요 원인인 락 대기를 방지합니다.

### (2) **분산 트랜잭션 제한**
- 트랜잭션이 노드 간 분산되는 경우 충돌 가능성이 높아질 수 있습니다. Galera는 한 노드에서 트랜잭션을 완료하도록 권장하여 데드락 가능성을 줄입니다.

### (3) **노드 실패 시 자동 복구**
- 데드락 상황이 노드 장애로 이어지는 경우, Galera는 해당 노드를 클러스터에서 격리하고 정상적인 노드만으로 서비스를 유지합니다.

---

## 4. **데드락 가능성을 줄이기 위한 권장 사항**

Galera Cluster에서 데드락 발생을 최소화하려면 다음 권장 사항을 따르는 것이 좋습니다:

### (1) **짧은 트랜잭션 유지**
- 트랜잭션이 짧을수록 충돌 가능성이 줄어듭니다. 가능한 한 단일 작업에 집중된 트랜잭션을 사용하세요.

### (2) **트랜잭션 충돌 가능성 낮추기**
- 동일한 데이터에 대해 여러 노드에서 동시에 쓰기 작업을 수행하지 않도록 설계합니다.
- 데이터 파티셔닝 또는 특정 노드에서만 쓰기 작업을 수행하도록 애플리케이션을 조정합니다.

### (3) **트랜잭션 격리 수준 조정**
- Galera는 기본적으로 `REPEATABLE-READ` 격리 수준을 사용합니다. 필요에 따라 `READ-COMMITTED`로 낮추어 충돌 가능성을 줄일 수 있습니다.

### (4) **워크로드 분석 및 모니터링**
- Galera Manager 또는 Prometheus와 같은 모니터링 도구를 사용하여 트랜잭션 충돌 빈도를 확인하고 문제를 사전에 감지합니다.

---

## 5. **한계와 주의 사항**

- **과도한 쓰기 트랜잭션**: 클러스터에 지나치게 많은 쓰기 트랜잭션이 몰리면 성능 병목이 발생할 수 있습니다.
- **네트워크 지연**: 노드 간 네트워크 지연이 크면 충돌 검증 과정이 느려지고, 데드락 가능성이 증가할 수 있습니다.

---

## **결론**
Galera Cluster는 데드락 문제를 전역 트랜잭션 순서 관리와 Write-Set 기반 충돌 검증을 통해 효과적으로 관리합니다. 그러나, 완벽하게 데드락을 방지하기 위해 워크로드 설계 및 운영 단계에서 충돌 가능성을 줄이는 설계가 중요합니다. Galera의 기본 동작과 위의 권장 사항을 활용하면 안정적인 HA 환경을 구현할 수 있습니다.

--- 질문5

질문: select for udpate 구문처럼 배타적 락을 사용했을 경우에도 락(Lock)을 사용하지 않고, Write-Set을 기반으로 동기화를 수행해?

답변: Galera Cluster에서 **`SELECT ... FOR UPDATE`**와 같은 배타적 락을 사용할 경우, Galera의 동작 방식은 전통적인 락 기반 데이터베이스와 다릅니다. Galera Cluster는 **락 자체를 클러스터 노드 간에 전파하지 않으며**, 대신 **Write-Set 기반의 동기화**를 통해 데이터 일관성과 충돌 관리를 수행합니다.

아래에 Galera에서 배타적 락이 동작하는 방식을 설명하겠습니다.

---

## 1. **`SELECT ... FOR UPDATE`와 Galera의 Write-Set**
`SELECT ... FOR UPDATE`는 트랜잭션 내에서 특정 데이터를 **배타적으로 잠금**하여 다른 트랜잭션이 해당 데이터를 읽거나 수정하지 못하도록 보장하는 SQL 구문입니다. Galera에서 이 구문을 사용할 때는 다음 사항을 고려해야 합니다:

- **로컬 락**: `SELECT ... FOR UPDATE`는 해당 노드에서만 **로컬 락(Local Lock)**으로 처리됩니다.
  - 이 락은 클러스터의 다른 노드에는 전파되지 않습니다.
  - 따라서 동일한 데이터를 다른 노드에서 `SELECT ... FOR UPDATE`로 잠그려고 하면 충돌이 발생할 수 있습니다.

- **Write-Set 동기화**: Galera는 락 대신 트랜잭션 커밋 시점에 **Write-Set 검증(Certification Process)**을 통해 충돌을 관리합니다.
  - 트랜잭션이 커밋되기 전까지는 다른 노드에서 해당 데이터에 대한 동작이 독립적으로 진행될 수 있습니다.
  - 커밋 시점에 Write-Set 충돌이 감지되면, 하나의 트랜잭션만 커밋되고 나머지는 롤백됩니다.

---

## 2. **`SELECT ... FOR UPDATE`의 실제 동작**
`SELECT ... FOR UPDATE`를 Galera Cluster에서 사용할 경우, 다음과 같은 동작 방식이 적용됩니다:

1. **락은 로컬 노드에만 적용**:
   - `SELECT ... FOR UPDATE`로 잠근 데이터는 **현재 노드에서만 유효**합니다.
   - 다른 노드에서는 해당 락을 인식하지 못하므로 동일 데이터에 대한 충돌 가능성이 존재합니다.

2. **트랜잭션 충돌 검증**:
   - 트랜잭션이 커밋될 때, Galera는 Write-Set을 검증하여 다른 트랜잭션과의 충돌 여부를 확인합니다.
   - 충돌이 발생하면 충돌한 트랜잭션은 롤백됩니다.

3. **락 전파 없음**:
   - 전통적인 마스터-슬레이브 구조에서처럼 락을 노드 간에 전파하지 않으므로, 클러스터 전체에서 락 기반의 강력한 동시성 제어를 보장하지 않습니다.

---

## 3. **Galera Cluster에서 배타적 락 사용 시 주의점**

### (1) **락 기반 동기화 부족**
Galera는 노드 간에 락 상태를 동기화하지 않기 때문에, `SELECT ... FOR UPDATE`를 사용하더라도 다음과 같은 문제가 발생할 수 있습니다:
- 두 노드에서 동일한 데이터를 잠그려고 시도하면 **트랜잭션 충돌**로 인해 커밋 시점에 하나의 트랜잭션이 롤백됩니다.
- 이는 락이 클러스터 전체에서 강제되지 않기 때문에 발생합니다.

### (2) **락 경합 대신 충돌 처리**
Galera는 락 대신 커밋 시점에서 Write-Set 검증을 통해 충돌을 해결하므로, 트랜잭션 경합이 많은 환경에서는 성능 저하와 롤백 증가가 발생할 수 있습니다.

---

## 4. **Galera에서 배타적 락을 안전하게 사용하는 방법**
Galera Cluster에서 `SELECT ... FOR UPDATE`와 같은 배타적 락을 안전하게 사용하려면 다음을 고려해야 합니다:

### **(1) 단일 노드에서 쓰기 작업 집중**
- 락과 관련된 트랜잭션은 단일 노드에서만 실행되도록 설정하여 충돌 가능성을 줄입니다.
- 다른 노드에서 읽기 작업만 수행하도록 애플리케이션을 설계합니다.

### **(2) 트랜잭션 크기 최소화**
- 짧은 트랜잭션으로 락 유지 시간을 최소화하여 충돌 가능성을 낮춥니다.

### **(3) 데이터 파티셔닝**
- 데이터를 파티셔닝하여 특정 노드에서만 특정 데이터에 접근하도록 설계합니다.

### **(4) Galera 특화 격리 수준 활용**
- Galera는 기본적으로 **`REPEATABLE-READ` 격리 수준**을 사용하며, 필요 시 **`READ-COMMITTED`**로 설정하여 충돌 가능성을 줄일 수 있습니다.

---

## 5. **Galera의 특성과 배타적 락의 한계**
Galera는 기본적으로 **락 기반 DBMS보다 충돌 허용 모델**에 가깝습니다. 락을 클러스터 전체에 적용하지 않는 이유는 다음과 같습니다:
- **글로벌 락 전파는 성능에 큰 영향을 미침**: 네트워크 지연으로 인해 클러스터 성능이 급격히 저하될 수 있습니다.
- **충돌 해결이 더 간단**: 락 대신 트랜잭션 커밋 시점에서 충돌을 해결하는 방식이 분산 환경에서 효율적입니다.

---

## 6. **결론**
`SELECT ... FOR UPDATE`와 같은 배타적 락을 사용해도 Galera Cluster는 노드 간 락 동기화를 수행하지 않으며, Write-Set 기반 동기화로 충돌을 관리합니다. 락이 클러스터 전체에 영향을 미치지 않으므로, 락이 필요한 워크로드에서는 **단일 노드에서 락을 처리하거나 데이터 파티셔닝 및 트랜잭션 최소화**를 통해 충돌 가능성을 줄이는 전략이 필요합니다. Galera의 설계는 락 기반 시스템보다 **글로벌 일관성보다 고가용성과 성능을 중시하는 구조**임을 명심해야 합니다.

--- 질문6

질문: Galera Cluster에서 멀티 마스터 구조로 설정했을 경우, 단일 노드에서 쓰기 작업 집중할 수 있는 방법이 있어?

답변: Galera Cluster에서 멀티 마스터 구조로 설정했을 때, 특정 노드에서 쓰기 작업을 집중하도록 구성하는 것은 가능합니다. 이를 통해 충돌 및 롤백 가능성을 줄이고, 클러스터의 안정성과 성능을 높일 수 있습니다. 아래는 단일 노드에서 쓰기 작업을 집중하도록 설정할 수 있는 몇 가지 방법입니다.

---

## **1. 클라이언트 라우팅을 통한 제어**
### 방법: 애플리케이션 레벨에서 특정 노드로 쓰기 요청을 라우팅
- **구현 방법**:
  - **쓰기 요청**: 특정 노드(Primary Node)로만 전달되도록 애플리케이션 또는 로드 밸런서를 설정.
  - **읽기 요청**: 나머지 노드(Read-Only Nodes)로 분산 처리.

#### 예시: 로드 밸런서 기반 라우팅
- **HAProxy 설정**:
  - 쓰기 노드(Primary)와 읽기 노드(Secondary)를 분리.
  - 쓰기 트래픽은 Primary Node로만 전달.
  ```haproxy
  frontend mysql_cluster
      bind *:3306
      acl is_write req.hdr(user-agent) -m sub write
      use_backend write_backend if is_write
      default_backend read_backend

  backend write_backend
      server primary_node 192.168.1.10:3306 check

  backend read_backend
      server read_node1 192.168.1.11:3306 check
      server read_node2 192.168.1.12:3306 check
  ```

#### 예시: JDBC URL 설정
```java
jdbc:mysql:loadbalance://192.168.1.10/<DB_NAME>?loadBalanceBlacklistTimeout=5000
```
- 쓰기 요청은 특정 노드에 우선적으로 전달하도록 클라이언트 라이브러리 설정.

---

## **2. 트랜잭션 라우팅 정책**
### 방법: Galera Cluster의 격리 수준과 트랜잭션 정책 활용
Galera는 모든 노드에서 쓰기가 가능하지만, 특정 노드에서만 트랜잭션을 시작하도록 설정할 수 있습니다.
- **격리 수준 설정**:
  - 특정 노드에서만 `REPEATABLE-READ` 또는 `READ-COMMITTED` 격리 수준으로 트랜잭션을 실행.
  - 나머지 노드는 읽기 전용 작업으로 제한.

#### 설정 방법:
1. **쓰기 전용 노드**:
   ```sql
   SET GLOBAL wsrep_reject_queries='NONE';
   ```
2. **읽기 전용 노드**:
   ```sql
   SET GLOBAL wsrep_reject_queries='ALL';
   ```
   또는
   ```sql
   SET GLOBAL wsrep_reject_queries='UPDATE';
   ```

---

## **3. 노드 기반 쓰기 제한**
### 방법: 클러스터 설정에서 특정 노드를 "쓰기 전용"으로 설정
Galera Cluster는 특정 노드에서의 쓰기 작업을 제한할 수 있는 설정을 제공합니다.

#### 설정 예시:
1. **클러스터 노드에서 쓰기 제한 적용**:
   - 특정 노드에서 쓰기 작업이 불가능하도록 설정.
   ```ini
   [mysqld]
   wsrep_reject_queries=ALL
   ```

2. **노드 레벨 읽기/쓰기 권한 분리**:
   - 클라이언트 인증 정보를 통해 쓰기 작업을 특정 노드로 제한.

---

## **4. 애플리케이션 레벨 분리**
### 방법: 쓰기 작업 전용 및 읽기 작업 전용 연결 풀 구성
애플리케이션에서 쓰기 작업과 읽기 작업을 분리된 연결 풀로 구성하여 특정 노드로 라우팅합니다.

#### 예시: Spring Boot 연결 설정
- **쓰기 작업 연결 풀**:
  ```yaml
  spring:
    datasource:
      url: jdbc:mysql://192.168.1.10:3306/db_write
      username: write_user
      password: write_password
  ```
- **읽기 작업 연결 풀**:
  ```yaml
  spring:
    datasource:
      url: jdbc:mysql:loadbalance://192.168.1.11,192.168.1.12:3306/db_read
      username: read_user
      password: read_password
  ```

---

## **5. 클러스터 구성 변경**
### 방법: 노드 상태 기반 쓰기 제한
Galera Cluster는 노드 상태를 기준으로 쓰기 작업을 제한할 수 있습니다.
- **Primary Component 상태**: 정상적인 노드에서만 쓰기 허용.
- **Donor 또는 Non-Primary Component 상태**: 읽기 전용 작업만 허용.

#### 설정:
1. 클러스터 상태 확인:
   ```sql
   SHOW STATUS LIKE 'wsrep_cluster_status';
   ```
   - **Primary** 상태인 노드에서만 쓰기 가능.

2. 상태 기반 쓰기 제한 설정:
   - 애플리케이션에서 `wsrep_cluster_status`를 주기적으로 확인하여 쓰기 작업을 특정 노드로 제한.

---

## **6. 백업 및 장애 복구 계획**
단일 노드에 쓰기를 집중할 경우, 해당 노드에 장애가 발생했을 때 다음 노드로 자동으로 전환되도록 구성해야 합니다.
- **Failover Mechanism**:
  - 로드 밸런서를 사용하여 자동으로 새로운 Primary 노드로 쓰기 트래픽을 전환.
  - 클러스터 상태를 기반으로 Active/Passive 구조를 설계.

---

## **결론**
Galera Cluster에서 단일 노드에 쓰기 작업을 집중하려면 **로드 밸런서 라우팅**, **노드 설정 변경**, **애플리케이션 레벨 제어**와 같은 방법을 사용할 수 있습니다. 이러한 접근 방식은 클러스터의 충돌을 줄이고, 성능을 최적화하며, 동시에 HA를 유지하는 데 기여합니다. 다만, 장애 복구 시 자동화된 전환(Failover)을 반드시 설정해야 시스템의 지속성을 보장할 수 있습니다.

--- 질문7

질문: Galera Cluster의 핵심 철학을 설명해줘.

답변: Galera Cluster의 핵심 철학은 **분산 시스템 환경에서 고가용성(High Availability)과 데이터 일관성(Data Consistency)을 보장하면서도 확장성(Scalability)을 제공**하는 데 있습니다. 이 철학은 Galera Cluster가 설계된 이유와 동작 원리의 모든 측면에 녹아있습니다. 이를 이해하기 위해 Galera Cluster의 핵심 철학을 아래와 같이 정리합니다.

---

## **1. 동기식 복제를 통한 데이터 일관성 보장**
Galera Cluster는 **동기식 복제(Synchronous Replication)**를 사용하여 모든 노드가 동일한 상태를 유지하도록 보장합니다.

- **Write-Set 기반 복제**:
  - 데이터 변경은 **Write-Set**으로 정의되어 클러스터 내 모든 노드에 전파됩니다.
  - 트랜잭션 커밋은 모든 노드가 Write-Set을 승인했을 때만 완료됩니다.
- **데이터 일관성 보장**:
  - 모든 노드는 항상 동일한 데이터 상태를 유지하며, 데이터 불일치(Inconsistency)가 발생하지 않습니다.

---

## **2. 멀티 마스터 구조 (Multi-Master Architecture)**
Galera Cluster는 모든 노드에서 쓰기 작업이 가능한 **멀티 마스터 구조**를 제공합니다.

- **특징**:
  - 어느 노드에서든 읽기/쓰기 작업을 수행할 수 있습니다.
  - 특정 노드에 쓰기 작업이 집중되지 않아 부하 분산이 가능합니다.
- **장점**:
  - 고가용성을 지원하며, 하나의 노드가 장애를 겪어도 다른 노드가 작업을 이어받아 서비스를 유지합니다.

---

## **3. 노드 간 충돌 감지 및 처리**
Galera Cluster는 분산 환경에서 필연적으로 발생할 수 있는 **트랜잭션 충돌**을 효율적으로 감지하고 관리합니다.

- **Certification Process**:
  - 트랜잭션 충돌은 커밋 시점에 감지되며, 충돌이 발생한 트랜잭션은 롤백됩니다.
  - 이는 충돌 관리를 중앙화하지 않고 각 노드에서 분산 처리하는 방식입니다.
- **충돌 방지 설계**:
  - 충돌을 최소화하기 위해 **글로벌 트랜잭션 순서(Global Transaction Ordering)**를 부여하여 트랜잭션 순서를 일관되게 관리합니다.

---

## **4. 고가용성 (High Availability, HA)**
Galera Cluster는 데이터베이스 서비스가 장애 없이 지속적으로 동작하도록 설계되었습니다.

- **자동 장애 복구**:
  - 노드가 장애로 인해 클러스터에서 제외되더라도, 정상적인 노드들이 서비스 연속성을 유지합니다.
  - 장애 노드가 복구되면, 자동으로 클러스터에 재합류하며 동기화가 이루어집니다.
- **Split-Brain 방지**:
  - Quorum 기반으로 클러스터 상태를 관리하여 Split-Brain 상황(노드가 서로 분리되어 데이터 일관성이 깨지는 상황)을 방지합니다.

---

## **5. 확장성 (Scalability)**
Galera Cluster는 확장성을 고려하여 설계되었으며, 특히 읽기 작업이 많은 워크로드에서 효율적입니다.

- **수평적 확장**:
  - 클러스터에 노드를 추가함으로써 읽기 성능을 쉽게 확장할 수 있습니다.
- **부하 분산**:
  - 멀티 마스터 구조를 활용해 쓰기 트래픽이 여러 노드에 분산될 수 있습니다.

---

## **6. 분산 시스템의 단순화**
Galera Cluster는 **분산 시스템의 복잡성을 최소화**하면서도 높은 신뢰성을 제공합니다.

- **단일 클러스터 뷰**:
  - 모든 노드는 동등한 역할을 가지며, 특별히 마스터 노드를 지정할 필요가 없습니다.
- **간단한 설정**:
  - 복잡한 분산 데이터베이스 설정 없이 기본적인 Galera 설정으로 클러스터를 구축할 수 있습니다.

---

## **7. 데이터베이스의 신뢰성 및 안정성**
Galera Cluster는 분산 데이터베이스의 신뢰성을 확보하기 위해 여러 안정성 메커니즘을 제공합니다.

- **Transaction ID 기반의 데이터 관리**:
  - 트랜잭션 ID를 기반으로 데이터 정합성을 유지합니다.
- **헬스 체크 및 자동 관리**:
  - 클러스터는 지속적으로 노드 상태를 확인하고, 비정상 노드를 격리하거나 복구합니다.

---

## **8. 워크로드 유연성**
Galera Cluster는 다양한 유형의 워크로드에서 효과적으로 작동합니다.

- **읽기 작업이 많은 워크로드**:
  - 노드 수를 늘려 읽기 성능을 높일 수 있습니다.
- **쓰기 트랜잭션 충돌 관리**:
  - 충돌이 적은 환경에서 멀티 마스터의 이점을 극대화할 수 있습니다.

---

## **Galera Cluster의 철학 요약**
Galera Cluster의 철학은 분산 데이터베이스가 가져야 할 세 가지 주요 목표를 중심으로 이루어집니다:
1. **고가용성**: 장애 상황에서도 서비스를 지속적으로 제공.
2. **데이터 일관성**: 클러스터 내 모든 노드가 동일한 데이터를 보장.
3. **확장성**: 요구에 따라 클러스터를 쉽게 확장 가능.

이 철학은 Galera Cluster가 분산 환경에서도 높은 신뢰성과 성능을 제공하며, 다양한 비즈니스 요구사항에 유연하게 대응할 수 있도록 설계된 이유입니다.

--- 질문8

질문: Write-Set 기반 복제, 글로벌 트랜잭션 순서(Global Transaction Ordering), Certification Process 가 멀티 마스터 클러스터링을 기본 설정으로 가져갈 수 있는 개념들로 보인다. 각 개념이 해결하고자 한 문제들을 설명해주고 세 개의 개념외에 빠진 개념이 있으면 추가해줘.

답변: Galera Cluster의 **Write-Set 기반 복제**, **글로벌 트랜잭션 순서(Global Transaction Ordering)**, 그리고 **Certification Process**는 멀티 마스터 클러스터링 환경에서 발생할 수 있는 다양한 문제를 해결하기 위해 설계된 핵심 개념들입니다. 이 개념들이 각각 해결하고자 한 문제들을 살펴보고, 빠진 개념이 있다면 추가로 설명하겠습니다.

---

## **1. Write-Set 기반 복제**
### 해결하고자 한 문제: **분산된 노드 간 데이터 동기화 및 일관성 보장**
- **문제**: 전통적인 복제 방식에서는 마스터-슬레이브 구조에서만 데이터 동기화가 가능하며, 멀티 마스터 환경에서는 데이터 충돌과 불일치 문제가 빈번하게 발생.
- **해결**:
  - Galera는 트랜잭션에서 발생한 데이터 변경사항을 **Write-Set**으로 정의하고, 이를 클러스터 내 모든 노드에 전파.
  - 각 노드는 Write-Set을 받아 데이터 일관성을 유지하며, 동기적으로 복제를 완료.
  - 트랜잭션이 커밋되기 전에 복제가 완료되므로 데이터 불일치 방지.

---

## **2. 글로벌 트랜잭션 순서 (Global Transaction Ordering)**
### 해결하고자 한 문제: **분산 트랜잭션의 순서 정렬**
- **문제**: 분산 환경에서 여러 노드에서 트랜잭션이 동시에 발생하면 트랜잭션 적용 순서가 달라질 수 있어 데이터 일관성이 깨질 위험.
- **해결**:
  - Galera는 클러스터 내 모든 노드에 **글로벌 트랜잭션 ID**를 부여하여 트랜잭션 순서를 일관되게 정렬.
  - Write-Set이 클러스터에 전파될 때, 트랜잭션 순서가 동기화되어 모든 노드가 동일한 순서로 트랜잭션을 처리.
  - 이를 통해 노드 간 데이터 일관성을 보장.

---

## **3. Certification Process**
### 해결하고자 한 문제: **트랜잭션 충돌 감지 및 처리**
- **문제**: 멀티 마스터 환경에서는 동일한 데이터에 대해 여러 노드에서 동시에 트랜잭션이 발생할 수 있으며, 이는 충돌과 데이터 불일치를 초래.
- **해결**:
  - 트랜잭션이 커밋되기 전에 Write-Set을 **Galera Certifier**에서 검증.
  - 다른 노드에서 이미 커밋된 트랜잭션과 충돌 여부를 확인.
  - 충돌이 발생하면 트랜잭션을 롤백하여 데이터 무결성을 유지.

---

## **추가 개념**

### **4. Quorum-Based Decision Making**
#### 해결하고자 한 문제: **Split-Brain 방지 및 클러스터 안정성**
- **문제**: 네트워크 분리(Split-Brain) 상황에서 클러스터가 분할되어 각기 다른 상태로 작동하면 데이터 불일치가 발생.
- **해결**:
  - Galera는 **Quorum(과반수 노드)** 기반으로 클러스터 상태를 결정.
  - 클러스터 노드의 과반수가 활성 상태일 때만 Primary Component로 간주하며, 클러스터 동작 유지.
  - 과반수를 충족하지 못한 Non-Primary Component는 쓰기 작업을 중단.

---

### **5. State Snapshot Transfer (SST) 및 Incremental State Transfer (IST)**
#### 해결하고자 한 문제: **새로운 노드 추가 및 장애 복구 시 데이터 동기화**
- **문제**: 클러스터에 새로운 노드를 추가하거나 장애 노드가 복구될 때 기존 노드와 데이터 동기화를 보장해야 함.
- **해결**:
  - Galera는 **SST(State Snapshot Transfer)**를 통해 전체 데이터를 새 노드에 복제.
  - 이미 클러스터에 참여했던 노드가 다시 합류하는 경우, **IST(Incremental State Transfer)**를 사용해 필요한 데이터만 복제하여 효율성을 향상.
  - 동기화 과정이 완료되기 전까지 노드는 클러스터에 참여하지 않음.

---

### **6. Flow Control**
#### 해결하고자 한 문제: **노드 간 성능 불균형 관리**
- **문제**: 노드 간 성능 차이로 인해 느린 노드가 처리 속도를 따라가지 못하면, 클러스터 전체의 동작에 영향을 미칠 수 있음.
- **해결**:
  - Galera는 **Flow Control** 메커니즘을 사용하여 느린 노드가 뒤처지지 않도록 쓰기 작업 속도를 조절.
  - 느린 노드가 데이터를 처리할 시간을 확보하도록 Write-Set 전파 속도를 제어.

---

### **7. Transaction-Based Consistency**
#### 해결하고자 한 문제: **일관성 모델 제공**
- **문제**: 분산 환경에서는 트랜잭션 일관성을 보장하는 것이 어려움.
- **해결**:
  - Galera는 `REPEATABLE-READ` 및 `READ-COMMITTED` 격리 수준을 지원하여 트랜잭션 기반의 일관성을 보장.
  - 트랜잭션 충돌이 발생하면 자동으로 감지하고 롤백.

---

## **총 정리**
### Galera Cluster의 핵심 개념과 해결된 문제
| 개념                          | 해결된 문제                                    |
|-------------------------------|-----------------------------------------------|
| **Write-Set 기반 복제**       | 분산 노드 간 데이터 동기화 및 불일치 방지     |
| **글로벌 트랜잭션 순서**      | 트랜잭션 순서 정렬로 데이터 일관성 유지       |
| **Certification Process**     | 트랜잭션 충돌 감지 및 처리                   |
| **Quorum-Based Decision Making** | Split-Brain 방지 및 클러스터 안정성         |
| **SST/IST**                   | 노드 추가 및 장애 복구 시 데이터 동기화       |
| **Flow Control**              | 노드 간 성능 불균형 관리                     |
| **Transaction-Based Consistency** | 트랜잭션 기반 데이터 일관성 보장          |

---

### **결론**
Galera Cluster는 분산 환경에서 멀티 마스터 클러스터링을 가능하게 하기 위해 설계된 다양한 메커니즘을 사용합니다. **Write-Set 복제, 글로벌 트랜잭션 순서, Certification Process**는 데이터 동기화와 충돌 관리의 핵심이지만, 이를 보완하는 **Quorum, SST/IST, Flow Control** 같은 메커니즘도 중요한 역할을 합니다. 이러한 개념들은 분산 환경에서의 안정성과 성능을 유지하며, 고가용성과 일관성을 보장합니다.

--- 질문9

질문: Galera Cluster는 분산 환경에서 멀티 마스터 클러스터링을 가능하게 하기 위해 설계된 다양한 메커니즘이 낙관적 락의 매커니즘과 비슷하게 보인다.

답변: 맞습니다. **Galera Cluster의 메커니즘은 낙관적 락(Optimistic Locking)과 유사한 개념**을 가지고 있습니다. Galera Cluster는 멀티 마스터 클러스터링에서 데이터 충돌을 최소화하고 일관성을 유지하기 위해, 낙관적 락의 철학을 기반으로 트랜잭션 검증과 충돌 해결을 처리합니다. 이를 자세히 살펴보겠습니다.

---

## **낙관적 락과 Galera Cluster의 유사성**

### 1. **낙관적 락의 개념**
- 낙관적 락은 트랜잭션이 충돌하지 않을 것이라고 가정하고, 별도의 락을 걸지 않고 데이터 작업을 진행합니다.
- 데이터 변경 작업이 완료된 후, **검증 단계**에서 충돌 여부를 확인합니다.
- 충돌이 발견되면 작업을 롤백하고, 필요 시 다시 시도하도록 처리합니다.

### 2. **Galera Cluster의 충돌 관리**
Galera Cluster도 **트랜잭션 충돌이 드물 것이라고 가정**하며, 트랜잭션 수행 중에 락을 사용하지 않고, **커밋 시점에서 검증(Certification Process)**을 통해 충돌 여부를 확인합니다.

- Galera는 **Write-Set Certification**이라는 과정을 통해 충돌을 감지합니다.
- Write-Set은 트랜잭션 중 변경된 데이터를 정의하며, 커밋 시점에 클러스터의 다른 노드들과 비교해 충돌 여부를 판단합니다.
- 충돌이 발생한 트랜잭션은 롤백됩니다.

---

## **Galera Cluster가 낙관적 락과 유사한 이유**

### **1. 락의 미사용**
- **낙관적 락**: 트랜잭션 실행 중 데이터에 락을 걸지 않음.
- **Galera Cluster**: 노드 간 데이터를 동기화하면서 데이터 락을 전파하지 않음.

### **2. 충돌 감지 방식**
- **낙관적 락**: 트랜잭션 종료 시점에 버전 번호나 해시 값을 비교하여 충돌을 감지.
- **Galera Cluster**: 커밋 시점에 Write-Set을 검증하여 충돌을 감지.

### **3. 롤백 처리**
- **낙관적 락**: 충돌 발생 시 트랜잭션을 롤백하고, 필요 시 재시도.
- **Galera Cluster**: 충돌한 트랜잭션을 롤백하고, 클라이언트에게 실패 응답을 반환.

---

## **낙관적 락과 Galera Cluster의 차이점**

| **구분**                 | **낙관적 락**                                                                                           | **Galera Cluster**                                                                                           |
|--------------------------|--------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|
| **적용 범위**            | 단일 데이터베이스나 테이블에서 적용.                                                                   | 분산된 클러스터 환경에서 적용.                                                                              |
| **충돌 검증 방식**       | 로컬 데이터의 버전 번호나 해시 값으로 검증.                                                            | 클러스터 내 모든 노드의 Write-Set과 비교하여 충돌 검증.                                                     |
| **락 전파**              | 애초에 락을 사용하지 않음.                                                                             | 락을 사용하지 않지만 동기 복제를 통해 데이터 일관성 보장.                                                   |
| **재시도 여부**          | 충돌 시 애플리케이션이 재시도를 처리해야 함.                                                           | 충돌 시 트랜잭션 롤백 후 클라이언트가 재시도 가능.                                                          |
| **분산 시스템 지원**     | 분산 환경에서는 별도의 설계가 필요.                                                                    | 분산 환경을 기본으로 설계되어 노드 간 데이터 동기화 및 충돌 해결을 지원.                                      |

---

## **낙관적 락의 철학이 Galera Cluster에 적합한 이유**

### **1. 멀티 마스터 구조에서 효율성**
- Galera는 모든 노드에서 읽기/쓰기 작업을 수행할 수 있는 멀티 마스터 구조를 지원합니다.
- 락을 노드 간에 전파하지 않음으로써 쓰기 작업의 병목을 최소화하고, 높은 동시성을 제공합니다.

### **2. 동기 복제를 통한 데이터 일관성**
- Galera는 트랜잭션 커밋 전에 Write-Set을 동기화하여 데이터 일관성을 보장합니다.
- 이는 락을 사용하지 않으면서도 데이터 충돌을 관리할 수 있도록 설계된 낙관적 락의 철학과 일치합니다.

### **3. 충돌이 드문 분산 환경에 적합**
- 대부분의 분산 시스템에서는 동일한 데이터에 대해 동시에 접근할 가능성이 상대적으로 낮습니다.
- Galera는 이러한 환경에서 낙관적 접근 방식을 사용하여 성능을 극대화합니다.

---

## **Galera Cluster의 추가적인 개선점**
낙관적 락의 철학을 확장한 Galera Cluster는 분산 환경에서의 특수한 문제를 해결하기 위해 다음과 같은 메커니즘도 제공합니다:

1. **글로벌 트랜잭션 순서(GTO)**:
   - 트랜잭션 순서를 통합적으로 관리하여 데이터 불일치 문제를 방지.
   
2. **Quorum**:
   - Split-Brain 상황에서 과반수 노드 기반으로 안정적인 클러스터 상태 유지.

3. **Flow Control**:
   - 느린 노드가 클러스터 성능에 영향을 미치지 않도록 데이터 처리 속도 조절.

4. **State Snapshot Transfer (SST)** 및 **Incremental State Transfer (IST)**:
   - 노드 추가 또는 복구 시 데이터를 효율적으로 동기화.

---

## **결론**
Galera Cluster는 낙관적 락의 철학(충돌은 드물며, 발생 시 처리 가능하다는 가정)을 확장하여 멀티 마스터 분산 데이터베이스 환경에 적합하도록 설계되었습니다. **Write-Set 기반 복제, 글로벌 트랜잭션 순서, Certification Process**는 이러한 철학의 구현을 돕는 핵심 요소로, 락 없이도 데이터 일관성과 고가용성을 보장합니다. 낙관적 락의 철학은 Galera Cluster의 효율성과 성능을 유지하는 데 매우 중요한 역할을 합니다.

